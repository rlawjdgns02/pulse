# 맥진 데이터를 이용한 한/열 체질 분류 프로젝트 (v2.0)

## 📋 프로젝트 개요

맥진기를 통해 수집한 정량적 맥파(Pulse Wave) 데이터를 활용하여, 한의학의 핵심 진단 기준인 '한(寒)'과 '열(熱)' 체질을 객관적으로 분류하는 머신러닝 모델을 개발합니다. 이 프로젝트는 전통적인 진단의 자동화 및 객관화 가능성을 탐구하는 것을 목표로 합니다.

## 🔍 데이터 정보

* **원본 데이터**: 좌수/우수 각각 98개의 가공된 맥파 파라미터
* **최종 사용 데이터**: 결측값 제거 후 **총 89명**의 데이터
* **클래스 분포**: 한(Cold): 43명, 열(Heat): 46명 (비교적 균형 잡힌 분포)

## 🎯 프로젝트 목표 및 현황

* **1차 목표**: 머신러닝을 통한 한/열 체질 분류 가능성 검증 → **(달성)**
* **2차 목표**: 안정적이고 신뢰도 높은 분류 모델 확보 → **(진행 중)**
* **현재 성능**:
   * **5-Fold 교차 검증 평균 정확도**: 약 **58% ~ 60%** (모델 및 특성 조합에 따라 변동, 높은 표준편차 보임)
   * **단일 테스트셋 최고 정확도**: **72.2%** (특정 데이터 분할에서 관찰된 최고 성능)
* **향후 계획**: 불안정한 성능을 개선하고 평균 70% 이상의 안정적인 성능을 확보하기 위한 특성 공학 및 데이터 증강 기법 적용

## 🔧 분석 파이프라인 및 주요 발견

본 프로젝트는 체계적인 실험을 통해 최적의 특성 조합과 모델을 탐색하는 과정을 거쳤습니다.

1. **1단계: 통계 기반 특성 선택 (Feature Selection)**
   * **방법**: 98개 전체 특성에 대해 t-검정, 순열 검정, ROC-AUC 분석을 교차 수행하여 '한/열' 분류에 통계적으로 가장 유의미한 특성을 탐색했습니다.
   * **결과**: **5개의 핵심 특성**을 1차 후보군으로 선별했습니다.

2. **2단계: 모델 벤치마킹 및 최적화**
   * **방법**: 선별된 특성 조합을 사용하여 SVM, RandomForest, XGBoost, AdaBoost, KNN 등 5개 모델에 대해 `GridSearchCV`를 통한 하이퍼파라미터 최적화를 수행했습니다.
   * **결과**: **SVM**과 **XGBoost**가 단일 테스트셋에서 **72.2%**의 가장 높은 성능을 보였으나, 5-Fold 교차 검증 시 **평균 60% 내외**의 성능을 보여 데이터가 가진 정보량의 한계를 확인했습니다.

3. **3단계: 외부 연구 벤치마킹**
   * **방법**: 관련 논문에서 효과적이었던 5개의 특성 조합을 우리 데이터에 적용하여 성능을 재평가했습니다.
   * **결과**: SVM 모델이 단일 테스트에서 동일한 **72.2%**의 정확도를 달성하며 **'한(寒)' 체질의 F1-Score를 67% → 71%로 개선**하여 분류 균형을 맞추는 데는 성공했으나, 교차 검증 성능은 여전히 60%대에 머물렀습니다.

4. **최종 결론**: 현재 데이터셋의 안정적인 성능 한계는 약 60%이며, 이를 돌파하기 위해서는 **모델 튜닝이 아닌 특성 공학(Feature Engineering)이 핵심**이라는 결론에 도달했습니다.

## ✨ 선택된 주요 특성 조합

두 가지의 유의미한 특성 조합을 발굴했습니다.

### 조합 A: 통계 기반 선택 (t-test Top 5)
* `Cardiac Output_left`
* `Pulse Pressure_left`
* `ECR_Left`
* `HRV_LH_ratio_Left`
* `W_R_Left`

### 조합 B: 논문 벤치마크 (성능 균형 우수)
* `h1/t1_left` (생성된 비율 특성)
* `H5_left`
* `T_left`
* `Ad_left`
* `T2_left`

## 📊 현재 최고 성능 모델 (신뢰도 기준)

* **모델**: **SVM (RBF 커널)**
* **특성 조합**: **조합 B (논문 벤치마크)**
* **성능**:
   * **5-Fold CV 평균 정확도**: **58.3%** (±12.9%)
   * **단일 테스트셋 최고 정확도**: 72.2%
   * **'한(Han)' F1-Score**: 70.6% (단일 테스트 기준)
   * **'열(Yeol)' F1-Score**: 73.7% (단일 테스트 기준)

## 📁 파일 구조

```
├── data/
│   ├── all_features_left.csv       # 좌수 전체 특성 (98개)
│   ├── all_features_right.csv      # 우수 전체 특성 (98개)
│   ├── labels_all_left.csv         # 좌수 라벨
│   └── labels_all_right.csv        # 우수 라벨
│
├── process/
│   ├── feature_creation.py         # 비율 특성 생성 및 데이터셋 저장
│   └── feature_selection.py        # t-test, Permutation, ROC-AUC 분석
│
├── models/
│   ├── svm_tuning_cv.py            # SVM + GridSearchCV + CV 평가
│   ├── xgboost_tuning_cv.py        # XGBoost + GridSearchCV + CV 평가
│   └── ... (다른 모델 평가 코드)
│
└── README.md
```

## 🛠️ 기술 스택

* **언어**: Python
* **주요 라이브러리**: `scikit-learn`, `pandas`, `numpy`, `matplotlib`, `seaborn`, `tqdm`
* **주요 모델**: `SVM`, `XGBoost`

## 📈 진행 상황 및 향후 과제

* [x] 데이터 전처리 및 탐색
* [x] 3가지 통계 기법을 통한 특성 선택 완료
* [x] 5개 주요 모델에 대한 하이퍼파라미터 최적화 및 교차 검증 완료
* [x] 외부 논문 특성 조합 벤치마킹 완료
* [ ] **(Next Step)** 특성 공학: 상호작용 특성, 비율 특성 추가 생성
* [ ] **(Next Step)** 데이터 증강: `SMOTE` 기법 적용 가능성 검토
* [ ] 목표 성능 (안정적인 75%+) 달성
* [ ] 허/실 체질 분류로 프로젝트 확장

## ⚠️ 한계 및 주의사항

* **작은 데이터셋 (89명)**으로 인한 과적합 및 모델 성능의 불안정성이 가장 큰 한계점입니다.
* 교차 검증 결과, 모델 성능이 데이터 분할에 따라 크게 변동(높은 표준편차)하는 것을 확인하여, **단일 테스트셋의 높은 점수(72.2%)를 맹신하기보다 평균 성능(약 60%)을 현실적인 지표로 삼아야 합니다.**