from xgboost import XGBClassifier, plot_importance
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import warnings
import time
import os
warnings.filterwarnings('ignore')

print("=== XGBoost CPU ì‚¬ìš©ëŸ‰ ì œì–´ GridSearch ===")

# ===== ğŸ”§ CPU ì‚¬ìš©ëŸ‰ ì„¤ì • (ì¤‘ìš”!) =====
CPU_USAGE = 'low'     # 'low', 'medium', 'high' ì¤‘ ì„ íƒ
SEARCH_MODE = 'full'  # 'fast', 'medium', 'full' ì¤‘ ì„ íƒ

print(f"ì„¤ì •: {SEARCH_MODE} íƒìƒ‰, {CPU_USAGE} CPU ì‚¬ìš©")

# ë°ì´í„° ë¡œë“œ
X = pd.read_csv('features_left.csv')
y = pd.read_csv('labels_left.csv')
y = y.astype(int)

# ë¼ë²¨ ê°’ í™•ì¸ ë° ì•ˆì „í•œ ì²˜ë¦¬
print(f"Original label distribution: {np.bincount(np.ravel(y))}")
print(f"Unique labels: {np.unique(np.ravel(y))}")

# ë¼ë²¨ì´ 1, 2ë¡œ ë˜ì–´ ìˆë‹¤ë©´ 0, 1ë¡œ ë³€í™˜ (scikit-learn í˜¸í™˜ì„±)
y_flat = np.ravel(y)
if set(np.unique(y_flat)) == {1, 2}:
    print("Converting labels from {1, 2} to {0, 1} for sklearn compatibility")
    y_flat = y_flat - 1  # 1,2 â†’ 0,1 ë³€í™˜
    label_mapping = {0: 'Han (Cold)', 1: 'Yeol (Heat)'}
    original_labels = {1: 'Han (Cold)', 2: 'Yeol (Heat)'}
else:
    label_mapping = {0: 'Han (Cold)', 1: 'Yeol (Heat)'}
    original_labels = {0: 'Han (Cold)', 1: 'Yeol (Heat)'}

print(f"Final label distribution: {np.bincount(y_flat)}")

# ë°ì´í„° ë¶„í•  - ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ train/testë§Œ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y_flat, test_size=0.2, random_state=42, stratify=y_flat
)

print(f"Training set size: {X_train.shape[0]}")
print(f"Test set size: {X_test.shape[0]}")
print(f"Total dataset size: {len(y_flat)}")

# ===== ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜ =====
print("\ní•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜...")

# ì˜µì…˜ 1: ë¹ ë¥¸ íƒìƒ‰ (48ê°œ ì¡°í•©, ì•½ 2-5ë¶„)
param_grid_fast = {
    'max_depth': [3, 4, 5],                    # 3ê°œ
    'n_estimators': [50, 100],                 # 2ê°œ
    'learning_rate': [0.1, 0.15],              # 2ê°œ
    'subsample': [0.8, 1.0],                   # 2ê°œ
    'colsample_bytree': [0.8, 1.0],            # 2ê°œ
}

# ì˜µì…˜ 2: ì¤‘ê°„ íƒìƒ‰ (192ê°œ ì¡°í•©, ì•½ 8-15ë¶„)
param_grid_medium = {
    'max_depth': [3, 4, 5, 6],                 # 4ê°œ
    'n_estimators': [50, 100, 150],            # 3ê°œ
    'learning_rate': [0.05, 0.1, 0.15],        # 3ê°œ
    'subsample': [0.7, 0.8, 1.0],              # 3ê°œ
    'colsample_bytree': [0.8, 1.0],            # 2ê°œ
    'min_child_weight': [1, 3]                 # 2ê°œ
}

# ì˜µì…˜ 3: ì „ì²´ íƒìƒ‰ (864ê°œ ì¡°í•©, ì•½ 30-60ë¶„)
param_grid_full = {
    'max_depth': [2, 3, 4, 5, 6],              # 5ê°œ
    'n_estimators': [50, 100, 150, 200],       # 4ê°œ
    'learning_rate': [0.05, 0.1, 0.15, 0.2],   # 4ê°œ
    'subsample': [0.7, 0.8, 0.9, 1.0],         # 4ê°œ
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],  # 4ê°œ
    'min_child_weight': [1, 3, 5],             # 3ê°œ
    'gamma': [0, 0.1, 0.2]                     # 3ê°œ
}

# ì›í•˜ëŠ” ì˜µì…˜ ì„ íƒ
if SEARCH_MODE == 'fast':
    param_grid = param_grid_fast
    print("ë¹ ë¥¸ íƒìƒ‰ ëª¨ë“œ ì„ íƒ")
elif SEARCH_MODE == 'medium':
    param_grid = param_grid_medium  
    print("ì¤‘ê°„ íƒìƒ‰ ëª¨ë“œ ì„ íƒ")
else:
    param_grid = param_grid_full
    print("ì „ì²´ íƒìƒ‰ ëª¨ë“œ ì„ íƒ")

# ì´ ì¡°í•© ê°œìˆ˜ ê³„ì‚°
total_combinations = 1
for key, values in param_grid.items():
    total_combinations *= len(values)
    print(f"{key}: {values}")

print(f"\nì´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ê°œìˆ˜: {total_combinations}ê°œ")

# ===== ğŸ’» CPU ì‚¬ìš©ëŸ‰ ì œì–´ ì„¤ì • =====
print("\nCPU ì‚¬ìš©ëŸ‰ ì„¤ì •...")

if CPU_USAGE == 'low':
    # CPU ì‚¬ìš©ëŸ‰ ìµœì†Œí™” (1ì½”ì–´ë§Œ ì‚¬ìš©, ê°€ì¥ ëŠë¦¼, ë‹¤ë¥¸ ì‘ì—… ê°€ëŠ¥)
    xgb_n_jobs = 1
    grid_n_jobs = 1
    time_multiplier = 3.0
    print("ğŸŒ ì €ì‚¬ìš© ëª¨ë“œ: CPU 1ì½”ì–´ë§Œ ì‚¬ìš© (ë‹¤ë¥¸ ì‘ì—… ê°€ëŠ¥)")
    
elif CPU_USAGE == 'medium':  
    # CPU ì‚¬ìš©ëŸ‰ ì¤‘ê°„ (ì ˆë°˜ ì½”ì–´ ì‚¬ìš©)
    cpu_count = os.cpu_count() or 4
    xgb_n_jobs = 1
    grid_n_jobs = max(1, cpu_count // 2)  # ì½”ì–´ì˜ ì ˆë°˜ë§Œ ì‚¬ìš©
    time_multiplier = 1.5
    print(f"âš–ï¸ ì¤‘ê°„ ì‚¬ìš© ëª¨ë“œ: CPU {grid_n_jobs}ì½”ì–´ ì‚¬ìš© (ì „ì²´ {cpu_count}ì½”ì–´ ì¤‘)")
    
else:
    # CPU ì‚¬ìš©ëŸ‰ ìµœëŒ€ (ëª¨ë“  ì½”ì–´ ì‚¬ìš©, ê°€ì¥ ë¹ ë¦„)
    xgb_n_jobs = 4
    grid_n_jobs = -1
    time_multiplier = 1.0
    print("ğŸš€ ê³ ì‚¬ìš© ëª¨ë“œ: ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš© (ë‹¤ë¥¸ ì‘ì—… ì–´ë ¤ì›€)")

# ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
estimated_minutes = (total_combinations * 3 * 0.05 / 60) * time_multiplier
print(f"â±ï¸ ì˜ˆìƒ ì†Œìš”ì‹œê°„: ì•½ {estimated_minutes:.1f}ë¶„")

# ===== ğŸ¯ XGBClassifier íŒŒë¼ë¯¸í„° ì„¤ì • =====
base_model = XGBClassifier(
    booster='gbtree',
    verbosity=0,  # ë¡œê·¸ ì¶œë ¥ ìµœì†Œí™”
    n_jobs=xgb_n_jobs,  # XGBoost ìì²´ CPU ì‚¬ìš©ëŸ‰ ì œí•œ
    random_state=42,
    eval_metric='logloss'
)

# ===== ğŸ” GridSearchCV ì„¤ì • =====
print(f"\nGridSearchCV ì„¤ì • ì¤‘...")
grid_search = GridSearchCV(
    estimator=base_model,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,  # ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ 3-fold
    n_jobs=grid_n_jobs,  # ì œí•œëœ ë³‘ë ¬ì²˜ë¦¬ â­ï¸ í•µì‹¬!
    verbose=1,  # ì§„í–‰ìƒí™© ì¶œë ¥
    return_train_score=True
)

print("GridSearchCV ì„¤ì • ì™„ë£Œ:")
print(f"- êµì°¨ê²€ì¦: 3-fold")
print(f"- CPU ì‚¬ìš©ëŸ‰: {CPU_USAGE} ëª¨ë“œ ({grid_n_jobs if grid_n_jobs != -1 else 'all'} ì½”ì–´)")
print(f"- XGBoost ìì²´: {xgb_n_jobs} ì½”ì–´")

# ===== ğŸš€ Grid Search ì‹¤í–‰ =====
print(f"\n=== GridSearch ì‹œì‘ ===")
print(f"ğŸ”„ {total_combinations}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸ ì¤‘...")
print("â° ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”... (Ctrl+Cë¡œ ì¤‘ë‹¨ ê°€ëŠ¥)")

start_time = time.time()

try:
    grid_search.fit(X_train, y_train)
    search_time = time.time() - start_time
    
    print(f"\nâœ… GridSearch ì™„ë£Œ!")
    print(f"- ì‹¤ì œ ì†Œìš” ì‹œê°„: {search_time/60:.1f}ë¶„")
    print(f"- í…ŒìŠ¤íŠ¸ëœ ì¡°í•©: {len(grid_search.cv_results_['params'])}ê°œ")
    
except KeyboardInterrupt:
    print(f"\nâ›” ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    print(f"- ì§„í–‰ ì‹œê°„: {(time.time() - start_time)/60:.1f}ë¶„")
    exit()

# ===== ğŸ“Š ìµœì  íŒŒë¼ë¯¸í„° ê²°ê³¼ ì¶œë ¥ =====
print("\n=== ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²°ê³¼ ===")

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("ğŸ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
for param, value in best_params.items():
    print(f"  {param}: {value}")

print(f"\nğŸ“Š ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: {best_score:.4f}")

# ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
y_pred_probs = best_model.predict_proba(X_test)[:, 1]

# ì„±ëŠ¥ í‰ê°€
accuracy = accuracy_score(y_test, y_pred)
print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥:")
print(f"Test Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)")
print(f"\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=list(label_mapping.values())))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print(f"\nConfusion Matrix:")
print(cm)

# ===== ğŸ† Top 10 íŒŒë¼ë¯¸í„° ì¡°í•© ë¶„ì„ =====
print(f"\n=== Top 10 Parameter Combinations ===")
results_df = pd.DataFrame(grid_search.cv_results_)
top_10 = results_df.nlargest(10, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]

print("ğŸ† ìƒìœ„ 10ê°œ ëª¨ë¸:")
print("-" * 80)
for i, (idx, row) in enumerate(top_10.iterrows(), 1):
    print(f"{i:2d}. Score: {row['mean_test_score']:.4f} (Â±{row['std_test_score']:.4f})")
    params_str = ', '.join([f"{k.replace('param_', '')}: {v}" for k, v in row['params'].items()])
    print(f"    {params_str}")

# ===== ğŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” =====
print("\n=== Feature Importance Visualization (Best Model) ===")
try:
    fig, ax = plt.subplots(figsize=(10, 8))
    plot_importance(best_model, ax=ax, max_num_features=15)
    ax.set_title('XGBoost Feature Importance (Best Model)')
    plt.tight_layout()
    plt.show()
except Exception as e:
    print(f"ì‹œê°í™” ì˜¤ë¥˜: {e}")

# íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ DataFrameìœ¼ë¡œ ì¶œë ¥
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': best_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\n=== Top 10 Most Important Features (Best Model) ===")
for i in range(min(10, len(feature_importance))):
    row = feature_importance.iloc[i]
    print(f"{i+1:2d}. {row['feature']:<30} : {row['importance']:.4f}")

# ===== ğŸ‰ ìµœì¢… ìš”ì•½ =====
print(f"\n=== ğŸ‰ ìµœì¢… ìš”ì•½ ===")

# ì„±ëŠ¥ í–¥ìƒ ë¹„êµ (ê¸°ë³¸ ëª¨ë¸ vs ìµœì  ëª¨ë¸)
print(f"ì„±ëŠ¥ ë¹„êµ:")
default_model = XGBClassifier(random_state=42, verbosity=0, n_jobs=1)
default_model.fit(X_train, y_train)
default_pred = default_model.predict(X_test)
default_accuracy = accuracy_score(y_test, default_pred)

print(f"- ê¸°ë³¸ XGBoost ì •í™•ë„:     {default_accuracy:.4f} ({default_accuracy*100:.1f}%)")
print(f"- ìµœì í™”ëœ XGBoost ì •í™•ë„:  {accuracy:.4f} ({accuracy*100:.1f}%)")

improvement = accuracy - default_accuracy
if improvement > 0:
    print(f"ğŸš€ ì„±ëŠ¥ í–¥ìƒ: +{improvement:.4f} (+{improvement*100:.1f}%p)")
else:
    print(f"ğŸ“‰ ì„±ëŠ¥ ë³€í™”: {improvement:.4f} ({improvement*100:.1f}%p)")

print(f"\nğŸ’¡ ì¶”ì²œ í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
for param, value in best_params.items():
    print(f"  {param}: {value}")

print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {search_time/60:.1f}ë¶„")
print(f"ğŸ’» CPU ì‚¬ìš© ëª¨ë“œ: {CPU_USAGE}")
print(f"ğŸ” íƒìƒ‰ ë²”ìœ„: {SEARCH_MODE}")

print(f"\nğŸ“ CPU ì‚¬ìš©ëŸ‰ ì œì–´ íŒ:")
print(f"- 'low': ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ìš© (1ì½”ì–´, ëŠë¦¼)")
print(f"- 'medium': ì¼ë°˜ ì‚¬ìš© (ì ˆë°˜ ì½”ì–´, ì ë‹¹)")  
print(f"- 'high': ìµœëŒ€ ì„±ëŠ¥ (ëª¨ë“  ì½”ì–´, ë¹ ë¦„)")