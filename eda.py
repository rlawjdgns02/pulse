import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import (
    f_classif, mutual_info_classif, SelectKBest, 
    VarianceThreshold, RFECV
)
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

print("=" * 80)
print("ì¢Œìˆ˜/ìš°ìˆ˜ ë¶„ë¦¬ íŠ¹ì„±ì„ íƒ + í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” + ë¹„êµë¶„ì„")
print("=" * 80)

# 1. ë°ì´í„° ë¡œë“œ
print("\n1. ë°ì´í„° ë¡œë“œ")
left_features = pd.read_csv('data/all_features_left.csv')
left_labels = pd.read_csv('data/labels_all_left.csv')
right_features = pd.read_csv('data/all_features_right.csv')
right_labels = pd.read_csv('data/labels_all_right.csv')

print(f"ì¢Œìˆ˜: {left_features.shape}, ìš°ìˆ˜: {right_features.shape}")

# 2. 4ë‹¨ê³„ íŠ¹ì„± ì„ íƒ í•¨ìˆ˜
def perform_feature_selection(features, labels, name):
    """4ë‹¨ê³„ íŠ¹ì„± ì„ íƒ"""
    print(f"\n{'='*60}")
    print(f"STEP 1: {name} íŠ¹ì„± ì„ íƒ")
    print(f"{'='*60}")
    
    X, y = features.copy(), labels.iloc[:, 0].copy()
    print(f"ì›ë³¸: {X.shape}, ë ˆì´ë¸” ë¶„í¬: {y.value_counts().to_dict()}")
    
    # 1ë‹¨ê³„: ë¶„ì‚° + ìƒê´€ê´€ê³„ í•„í„°ë§
    variance_filter = VarianceThreshold(threshold=0.01)
    X_step1a = variance_filter.fit_transform(X)
    X_step1 = pd.DataFrame(X_step1a, columns=X.columns[variance_filter.get_support()])
    
    # ìƒê´€ê´€ê³„ ì œê±°
    corr_matrix = X_step1.corr()
    high_corr_features = set()
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if abs(corr_matrix.iloc[i, j]) > 0.9:
                high_corr_features.add(corr_matrix.columns[j])
    
    X_step1_final = X_step1.drop(columns=high_corr_features)
    print(f"1ë‹¨ê³„: {X.shape[1]} â†’ {X_step1_final.shape[1]}ê°œ")
    
    # 2ë‹¨ê³„: ë¹„ì„ í˜• íŠ¹ì„± ì„ íƒ (F-score + Mutual Information)
    print(f"2ë‹¨ê³„: ë¹„ì„ í˜• íŠ¹ì„± ì„ íƒ")
    print("-" * 30)
    
    # F-score (ì„ í˜•)
    f_scores, p_values = f_classif(X_step1_final, y)
    f_series = pd.Series(f_scores, index=X_step1_final.columns)
    
    # Mutual Information (ë¹„ì„ í˜•)
    mi_scores = mutual_info_classif(X_step1_final, y, random_state=42)
    mi_series = pd.Series(mi_scores, index=X_step1_final.columns)
    
    # ìˆœìœ„ ê²°í•©
    f_ranking = f_series.rank(ascending=False)
    mi_ranking = mi_series.rank(ascending=False)
    combined_ranking = mi_ranking
    combined_ranking = combined_ranking.sort_values()
    
    print(f"   F-score 1ìœ„: {f_series.idxmax()} (ì ìˆ˜: {f_series.max():.3f})")
    print(f"   MI 1ìœ„: {mi_series.idxmax()} (ì ìˆ˜: {mi_series.max():.3f})")
    print(f"   ê²°í•© 1ìœ„: {combined_ranking.index[0]}")
    
    # í†µê³„ì  ìœ ì˜ì„± ê³ ë ¤
    significant_features = X_step1_final.columns[p_values < 0.05]
    print(f"   í†µê³„ì  ìœ ì˜ íŠ¹ì„±: {len(significant_features)}ê°œ")
    
    if len(significant_features) >= 8:
        significant_ranking = combined_ranking[significant_features]
        selected_features = significant_ranking.head(min(20, len(significant_features))).index.tolist()
        print(f"   â†’ ìœ ì˜í•œ íŠ¹ì„± ì¤‘ ìƒìœ„ {len(selected_features)}ê°œ ì„ íƒ")
    else:
        selected_features = combined_ranking.head(15).index.tolist()
        print(f"   â†’ ì „ì²´ íŠ¹ì„± ì¤‘ ìƒìœ„ {len(selected_features)}ê°œ ì„ íƒ")
    
    X_step2 = X_step1_final[selected_features]
    print(f"2ë‹¨ê³„: {X_step1_final.shape[1]} â†’ {X_step2.shape[1]}ê°œ")
    
    # 3ë‹¨ê³„: L1 ì •ê·œí™”
    scaler = StandardScaler()
    X_step2_scaled = scaler.fit_transform(X_step2)
    
    best_result = None
    best_score = 0
    
    for C in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]:
        lasso = LogisticRegression(penalty='l1', solver='liblinear', C=C, random_state=42)
        lasso.fit(X_step2_scaled, y)
        
        selected_mask = lasso.coef_[0] != 0
        if np.sum(selected_mask) > 0:
            cv_score = cross_val_score(lasso, X_step2_scaled, y, cv=5).mean()
            if cv_score > best_score:
                best_score = cv_score
                best_result = {'C': C, 'features': X_step2.columns[selected_mask].tolist()}
    
    X_step3 = X_step2[best_result['features']] if best_result else X_step2
    print(f"3ë‹¨ê³„: {X_step2.shape[1]} â†’ {X_step3.shape[1]}ê°œ")
    
    # 4ë‹¨ê³„: Random Forest RFECV (ë¹„ì„ í˜•)
    print(f"4ë‹¨ê³„: ë¹„ì„ í˜• RFECV (Random Forest)")
    print("-" * 30)
    
    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    min_features = max(2, X_step3.shape[1] // 4)
    
    rfecv = RFECV(rf, step=1, cv=5, scoring='accuracy',
                  min_features_to_select=min_features, n_jobs=-1)
    
    X_step3_scaled = StandardScaler().fit_transform(X_step3)
    rfecv.fit(X_step3_scaled, y)
    
    X_final = X_step3.iloc[:, rfecv.support_]
    final_features = X_step3.columns[rfecv.support_]
    
    print(f"4ë‹¨ê³„: {X_step3.shape[1]} â†’ {X_final.shape[1]}ê°œ")
    print(f"{name} ë¹„ì„ í˜• íŠ¹ì„±ì„ íƒ ì™„ë£Œ: {len(final_features)}ê°œ íŠ¹ì„±")
    
    return X_final, y, final_features.tolist()

# 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œì„œì¹˜ í•¨ìˆ˜
def perform_grid_search(X, y, name):
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œì„œì¹˜ + ì‹œê°í™”"""
    print(f"\n{'='*60}")
    print(f"STEP 2: {name} í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œì„œì¹˜")
    print(f"{'='*60}")
    
    # Train/Test ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ì»¤ë„ë³„ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
    param_grids = [
        {'kernel': ['linear'], 'C': [0.1, 1, 10, 100, 1000]},
        {'kernel': ['rbf'], 'C': [0.1, 1, 10, 100, 1000], 
         'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001, 0.0001]},
        {'kernel': ['poly'], 'C': [0.1, 1, 10, 100], 
         'gamma': ['scale', 'auto', 1, 0.1, 0.01], 'degree': [2, 3, 4]},
        {'kernel': ['sigmoid'], 'C': [0.1, 1, 10, 100], 
         'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001]}
    ]
    
    scoring = {'accuracy': 'accuracy', 'f1_macro': 'f1_macro', 'precision_macro': 'precision_macro'}
    
    print("ê·¸ë¦¬ë“œì„œì¹˜ ì‹¤í–‰ì¤‘...")
    grid_search = GridSearchCV(
        SVC(random_state=42), param_grids, cv=5, 
        scoring=scoring, refit='f1_macro', n_jobs=-1, verbose=0
    )
    
    grid_search.fit(X_train_scaled, y_train)
    
    # í…ŒìŠ¤íŠ¸ ì„±ëŠ¥
    test_accuracy = grid_search.best_estimator_.score(X_test_scaled, y_test)
    
    print(f"ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")
    print(f"CV F1-Score: {grid_search.best_score_:.4f}")
    print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
    
    # ì»¤ë„ë³„ ì„±ëŠ¥ ë¶„ì„
    results_df = pd.DataFrame(grid_search.cv_results_)
    kernel_performance = {}
    
    for kernel in ['linear', 'rbf', 'poly', 'sigmoid']:
        kernel_results = results_df[results_df['param_kernel'] == kernel]
        if len(kernel_results) > 0:
            best_idx = kernel_results['mean_test_f1_macro'].idxmax()
            best_result = results_df.loc[best_idx]
            
            kernel_performance[kernel] = {
                'f1_score': best_result['mean_test_f1_macro'],
                'accuracy': best_result['mean_test_accuracy'],
                'precision': best_result['mean_test_precision_macro'],
                'params': {k.replace('param_', ''): v for k, v in best_result.items() 
                          if k.startswith('param_')}
            }
    
    return {
        'name': name,
        'best_params': grid_search.best_params_,
        'best_score': grid_search.best_score_,
        'test_accuracy': test_accuracy,
        'kernel_performance': kernel_performance,
        'results_df': results_df
    }

# 4. ì‹œê°í™” í•¨ìˆ˜
def create_grid_search_heatmap(results_df, name):
    """ê·¸ë¦¬ë“œì„œì¹˜ ê²°ê³¼ íˆíŠ¸ë§µ"""
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'{name} í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œì„œì¹˜ ê²°ê³¼', fontsize=16, fontweight='bold')
    
    kernels = ['linear', 'rbf', 'poly', 'sigmoid']
    axes = axes.flatten()
    
    for i, kernel in enumerate(kernels):
        kernel_results = results_df[results_df['param_kernel'] == kernel]
        
        if len(kernel_results) == 0:
            axes[i].text(0.5, 0.5, f'{kernel} ê²°ê³¼ ì—†ìŒ', ha='center', va='center', 
                        transform=axes[i].transAxes)
            axes[i].set_title(f'{kernel.upper()} ì»¤ë„')
            continue
        
        if kernel == 'linear':
            c_values = sorted(kernel_results['param_C'].unique())
            f1_scores = []
            
            for c in c_values:
                score = kernel_results[kernel_results['param_C'] == c]['mean_test_f1_macro'].iloc[0]
                f1_scores.append(score)
            
            axes[i].bar(range(len(c_values)), f1_scores, alpha=0.7, color='skyblue')
            axes[i].set_xticks(range(len(c_values)))
            axes[i].set_xticklabels([str(c) for c in c_values])
            axes[i].set_xlabel('C ê°’')
            axes[i].set_ylabel('F1-Score')
            
            for j, score in enumerate(f1_scores):
                axes[i].text(j, score + 0.005, f'{score:.3f}', ha='center', va='bottom')
        
        elif kernel in ['rbf', 'sigmoid']:
            try:
                pivot_table = kernel_results.pivot_table(
                    values='mean_test_f1_macro',
                    index='param_gamma',
                    columns='param_C',
                    aggfunc='mean'
                )
                
                string_gammas = [g for g in pivot_table.index if isinstance(g, str)]
                numeric_gammas = [g for g in pivot_table.index if not isinstance(g, str)]
                gamma_order = sorted(string_gammas) + sorted(numeric_gammas, reverse=True)
                pivot_table = pivot_table.reindex(gamma_order)
                
                sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='viridis',
                           ax=axes[i], cbar_kws={'label': 'F1-Score'})
                axes[i].set_xlabel('C ê°’')
                axes[i].set_ylabel('Gamma ê°’')
            except:
                axes[i].text(0.5, 0.5, f'{kernel} íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨', ha='center', va='center',
                            transform=axes[i].transAxes)
        
        else:  # poly
            degrees = sorted(kernel_results['param_degree'].unique())
            if len(degrees) == 1:
                degree = degrees[0]
                degree_results = kernel_results[kernel_results['param_degree'] == degree]
                try:
                    pivot_table = degree_results.pivot_table(
                        values='mean_test_f1_macro',
                        index='param_gamma',
                        columns='param_C',
                        aggfunc='mean'
                    )
                    
                    string_gammas = [g for g in pivot_table.index if isinstance(g, str)]
                    numeric_gammas = [g for g in pivot_table.index if not isinstance(g, str)]
                    gamma_order = sorted(string_gammas) + sorted(numeric_gammas, reverse=True)
                    pivot_table = pivot_table.reindex(gamma_order)
                    
                    sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='viridis',
                               ax=axes[i], cbar_kws={'label': 'F1-Score'})
                    axes[i].set_xlabel('C ê°’')
                    axes[i].set_ylabel('Gamma ê°’')
                    axes[i].set_title(f'{kernel.upper()} (degree={degree})')
                except:
                    axes[i].text(0.5, 0.5, f'{kernel} íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨', ha='center', va='center',
                                transform=axes[i].transAxes)
            else:
                axes[i].text(0.5, 0.5, f'{kernel}\në‹¤ì¤‘ degree', ha='center', va='center',
                            transform=axes[i].transAxes)
        
        if 'set_title' not in locals() or kernel != 'poly':
            axes[i].set_title(f'{kernel.upper()} ì»¤ë„')
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{name}_gridsearch_heatmap.png', dpi=300, bbox_inches='tight')
    plt.show()

# 5. ì‹¤í–‰: ì¢Œìˆ˜ ë¶„ì„
print("\n" + "="*80)
print("ì¢Œìˆ˜ ë°ì´í„° ë¶„ì„ ì‹œì‘")
print("="*80)

left_X, left_y, left_features = perform_feature_selection(left_features, left_labels, "ì¢Œìˆ˜")
left_grid_results = perform_grid_search(left_X, left_y, "ì¢Œìˆ˜")

create_grid_search_heatmap(left_grid_results['results_df'], "ì¢Œìˆ˜")

# 6. ì‹¤í–‰: ìš°ìˆ˜ ë¶„ì„  
print("\n" + "="*80)
print("ìš°ìˆ˜ ë°ì´í„° ë¶„ì„ ì‹œì‘")
print("="*80)

right_X, right_y, right_features = perform_feature_selection(right_features, right_labels, "ìš°ìˆ˜")
right_grid_results = perform_grid_search(right_X, right_y, "ìš°ìˆ˜")

create_grid_search_heatmap(right_grid_results['results_df'], "ìš°ìˆ˜")

# 7. STEP 3: ìµœì¢… ë¹„êµ ë° ì •ë¦¬
print("\n" + "="*80)
print("STEP 3: ìµœì¢… ê²°ê³¼ ë¹„êµ ë° ì •ë¦¬")
print("="*80)

print(f"\nğŸ“‹ ì„ íƒëœ íŠ¹ì„± ë¦¬ìŠ¤íŠ¸")
print("-" * 60)

print(f"\nì¢Œìˆ˜ íŠ¹ì„± ({len(left_features)}ê°œ):")
for i, feature in enumerate(left_features, 1):
    print(f"  {i:2d}. {feature}")

print(f"\nìš°ìˆ˜ íŠ¹ì„± ({len(right_features)}ê°œ):")  
for i, feature in enumerate(right_features, 1):
    print(f"  {i:2d}. {feature}")

common_features = set(left_features) & set(right_features)
print(f"\nê³µí†µ íŠ¹ì„± ({len(common_features)}ê°œ):")
if common_features:
    for i, feature in enumerate(sorted(common_features), 1):
        print(f"  {i:2d}. {feature}")
else:
    print("  ì—†ìŒ")

print(f"\nâš™ï¸ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¹„êµí‘œ")
print("-" * 80)

comparison_table = pd.DataFrame({
    'í•­ëª©': ['ë°ì´í„°', 'íŠ¹ì„±ê°œìˆ˜', 'ìµœì ì»¤ë„', 'Cê°’', 'Gamma', 'Degree', 'CV F1-Score', 'í…ŒìŠ¤íŠ¸ì •í™•ë„'],
    'ì¢Œìˆ˜': [
        'ì¢Œìˆ˜',
        len(left_features),
        left_grid_results['best_params']['kernel'],
        left_grid_results['best_params']['C'],
        left_grid_results['best_params'].get('gamma', 'N/A'),
        left_grid_results['best_params'].get('degree', 'N/A'),
        f"{left_grid_results['best_score']:.4f}",
        f"{left_grid_results['test_accuracy']:.4f}"
    ],
    'ìš°ìˆ˜': [
        'ìš°ìˆ˜',
        len(right_features),
        right_grid_results['best_params']['kernel'],
        right_grid_results['best_params']['C'],
        right_grid_results['best_params'].get('gamma', 'N/A'),
        right_grid_results['best_params'].get('degree', 'N/A'),
        f"{right_grid_results['best_score']:.4f}",
        f"{right_grid_results['test_accuracy']:.4f}"
    ]
})

print(comparison_table.to_string(index=False))

def create_final_comparison():
    """ìµœì¢… ë¹„êµ ì‹œê°í™”"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('ì¢Œìˆ˜ vs ìš°ìˆ˜ ì¢…í•© ë¹„êµ', fontsize=16, fontweight='bold')
    
    metrics = ['CV F1-Score', 'í…ŒìŠ¤íŠ¸ ì •í™•ë„']
    left_scores = [left_grid_results['best_score'], left_grid_results['test_accuracy']]
    right_scores = [right_grid_results['best_score'], right_grid_results['test_accuracy']]
    
    x = np.arange(len(metrics))
    width = 0.35
    
    ax1.bar(x - width/2, left_scores, width, label='ì¢Œìˆ˜', alpha=0.8, color='skyblue')
    ax1.bar(x + width/2, right_scores, width, label='ìš°ìˆ˜', alpha=0.8, color='lightcoral')
    
    ax1.set_xlabel('í‰ê°€ ì§€í‘œ')
    ax1.set_ylabel('ì ìˆ˜')
    ax1.set_title('ì„±ëŠ¥ ë¹„êµ')
    ax1.set_xticks(x)
    ax1.set_xticklabels(metrics)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    for i, (left, right) in enumerate(zip(left_scores, right_scores)):
        ax1.text(i - width/2, left + 0.01, f'{left:.3f}', ha='center', va='bottom')
        ax1.text(i + width/2, right + 0.01, f'{right:.3f}', ha='center', va='bottom')
    
    left_kernels = list(left_grid_results['kernel_performance'].keys())
    left_f1_scores = [left_grid_results['kernel_performance'][k]['f1_score'] for k in left_kernels]
    
    ax2.bar(left_kernels, left_f1_scores, alpha=0.8, color='skyblue')
    ax2.set_xlabel('ì»¤ë„')
    ax2.set_ylabel('F1-Score')
    ax2.set_title('ì¢Œìˆ˜ ì»¤ë„ë³„ ì„±ëŠ¥')
    ax2.grid(True, alpha=0.3)
    
    for i, score in enumerate(left_f1_scores):
        ax2.text(i, score + 0.005, f'{score:.3f}', ha='center', va='bottom')
    
    right_kernels = list(right_grid_results['kernel_performance'].keys())
    right_f1_scores = [right_grid_results['kernel_performance'][k]['f1_score'] for k in right_kernels]
    
    ax3.bar(right_kernels, right_f1_scores, alpha=0.8, color='lightcoral')
    ax3.set_xlabel('ì»¤ë„')
    ax3.set_ylabel('F1-Score')
    ax3.set_title('ìš°ìˆ˜ ì»¤ë„ë³„ ì„±ëŠ¥')
    ax3.grid(True, alpha=0.3)
    
    for i, score in enumerate(right_f1_scores):
        ax3.text(i, score + 0.005, f'{score:.3f}', ha='center', va='bottom')
    
    feature_data = ['ì¢Œìˆ˜', 'ìš°ìˆ˜']
    feature_counts = [len(left_features), len(right_features)]
    
    bars = ax4.bar(feature_data, feature_counts, alpha=0.8, color=['skyblue', 'lightcoral'])
    ax4.set_xlabel('ë°ì´í„° ìœ í˜•')
    ax4.set_ylabel('íŠ¹ì„± ê°œìˆ˜')
    ax4.set_title('ì„ íƒëœ íŠ¹ì„± ê°œìˆ˜')
    ax4.grid(True, alpha=0.3)
    
    for bar, count in zip(bars, feature_counts):
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                str(count), ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('final_left_right_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

create_final_comparison()

if left_grid_results['best_score'] > right_grid_results['best_score']:
    winner = "ì¢Œìˆ˜"
    winner_score = left_grid_results['best_score']
    winner_features = left_features
    winner_params = left_grid_results['best_params']
else:
    winner = "ìš°ìˆ˜"
    winner_score = right_grid_results['best_score']
    winner_features = right_features
    winner_params = right_grid_results['best_params']

print(f"\nğŸ† ìµœì¢… ê²°ê³¼")
print("-" * 50)
print(f"ìŠ¹ì: {winner} ë°ì´í„°")
print(f"ìµœê³  ì„±ëŠ¥: F1-Score {winner_score:.4f}")
print(f"íŠ¹ì„± ê°œìˆ˜: {len(winner_features)}ê°œ")
print(f"ìµœì  íŒŒë¼ë¯¸í„°: {winner_params}")

print(f"\nğŸ’¾ ë³µì‚¬ìš© ìµœì¢… ì„¤ì •")
print("-" * 50)
print(f"# ìµœê³  ì„±ëŠ¥ ì„¤ì •")
print(f"winner_data = '{winner}'")
print(f"best_features = {winner_features}")
print(f"best_params = {winner_params}")
print(f"best_score = {winner_score:.4f}")

print(f"\n# ì¢Œìˆ˜ ì„¤ì •")
print(f"left_features = {left_features}")
print(f"left_params = {left_grid_results['best_params']}")

print(f"\n# ìš°ìˆ˜ ì„¤ì •")
print(f"right_features = {right_features}")
print(f"right_params = {right_grid_results['best_params']}")

print(f"\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
print(f"ìƒì„±ëœ íŒŒì¼: ì¢Œìˆ˜_gridsearch_heatmap.png, ìš°ìˆ˜_gridsearch_heatmap.png, final_left_right_comparison.png")