import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV, train_test_split, validation_curve, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("=== LogisticRegression í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë° ì‹œê°í™” ===")

# ë°ì´í„° ë¡œë“œ (39ê°œ íŠ¹ì„±ìœ¼ë¡œ ëœ CSV íŒŒì¼)
X = pd.read_csv('features_left.csv')  # 39ê°œ íŠ¹ì„± íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •
y = pd.read_csv('labels_left.csv')  # ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •
y = y.astype(int)

# ë¼ë²¨ ì²˜ë¦¬
y_flat = np.ravel(y)
if set(np.unique(y_flat)) == {1, 2}:
    y_flat = y_flat - 1
    print("ë¼ë²¨ ë³€í™˜: {1,2} â†’ {0,1}")

print(f"ë°ì´í„° í¬ê¸°: {X.shape}")
print(f"í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_flat)}")

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y_flat, test_size=0.2, random_state=42, stratify=y_flat
)

# ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ")

# 1. í¬ê´„ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
print(f"\n1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •")
print("-" * 50)

# ê° solverë³„ë¡œ ì§€ì›í•˜ëŠ” penaltyì™€ ì¡°í•©
param_grid = [
    # liblinear solver (L1, L2 ì§€ì›)
    {
        'solver': ['liblinear'],
        'penalty': ['l1', 'l2'],
        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],
        'max_iter': [1000, 2000]
    },
    # saga solver (L1, L2, elasticnet ì§€ì›)
    {
        'solver': ['saga'],
        'penalty': ['l1', 'l2', 'elasticnet'],
        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],
        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],  # elasticnetìš©
        'max_iter': [1000, 2000, 5000]
    },
    # lbfgs solver (L2ë§Œ ì§€ì›, ê¸°ë³¸ê°’)
    {
        'solver': ['lbfgs'],
        'penalty': ['l2'],
        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],
        'max_iter': [1000, 2000, 5000]
    }
]

total_combinations = 0
for grid in param_grid:
    combinations = 1
    for key, values in grid.items():
        if key == 'l1_ratio' and 'elasticnet' in grid.get('penalty', []):
            combinations *= len(values)
        elif key != 'l1_ratio':
            combinations *= len(values)
    total_combinations += combinations

print(f"ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜: {total_combinations}ê°œ")

# 2. GridSearchCV ì‹¤í–‰
print(f"\n2. GridSearchCV ì‹¤í–‰")
print("-" * 50)

grid_search = GridSearchCV(
    LogisticRegression(random_state=42),
    param_grid,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

print("GridSearchCV ì‹¤í–‰ ì¤‘...")
grid_search.fit(X_train_scaled, y_train)

print(f"\nìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")
print(f"ìµœì  CV ì ìˆ˜: {grid_search.best_score_:.4f} ({grid_search.best_score_*100:.1f}%)")

# í…ŒìŠ¤íŠ¸ ì„±ëŠ¥
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test_scaled)
test_accuracy = accuracy_score(y_test, y_pred)

print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f} ({test_accuracy*100:.1f}%)")
print(f"CV vs í…ŒìŠ¤íŠ¸ ì°¨ì´: {abs(grid_search.best_score_ - test_accuracy)*100:.1f}%p")

# 3. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”
print(f"\n3. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”")
print("-" * 50)

results_df = pd.DataFrame(grid_search.cv_results_)

# ìƒìœ„ 10ê°œ ê²°ê³¼
top_10 = results_df.nlargest(10, 'mean_test_score')
print("\nìƒìœ„ 10ê°œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©:")
for i, (idx, row) in enumerate(top_10.iterrows(), 1):
    params_str = ', '.join([f"{k.replace('param_', '')}: {v}" for k, v in row.items() 
                           if k.startswith('param_')])
    print(f"{i:2d}. ì ìˆ˜: {row['mean_test_score']:.4f} | {params_str}")

# 4. ê²©ìíŒ ì‹œê°í™”
fig, axes = plt.subplots(2, 3, figsize=(20, 12))
fig.suptitle('LogisticRegression í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼', fontsize=16, fontweight='bold')

# 4-1. Solverë³„ ì„±ëŠ¥ ë¹„êµ
ax1 = axes[0, 0]
solver_performance = results_df.groupby('param_solver')['mean_test_score'].agg(['mean', 'max', 'std'])
solver_names = solver_performance.index
x_pos = np.arange(len(solver_names))

bars = ax1.bar(x_pos, solver_performance['mean'], 
               yerr=solver_performance['std'], capsize=5, alpha=0.7, color='skyblue')
ax1.set_xlabel('Solver')
ax1.set_ylabel('í‰ê·  CV ì ìˆ˜')
ax1.set_title('Solverë³„ ì„±ëŠ¥ ë¹„êµ')
ax1.set_xticks(x_pos)
ax1.set_xticklabels(solver_names)

# ë§‰ëŒ€ ìœ„ì— ìˆ˜ì¹˜ í‘œì‹œ
for i, (bar, mean_val, max_val) in enumerate(zip(bars, solver_performance['mean'], solver_performance['max'])):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
             f'í‰ê· : {mean_val:.3f}\nìµœê³ : {max_val:.3f}', ha='center', va='bottom', fontsize=9)

# 4-2. C ê°’ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” (penaltyë³„)
ax2 = axes[0, 1]
for penalty in ['l1', 'l2']:
    penalty_data = results_df[results_df['param_penalty'] == penalty]
    if len(penalty_data) > 0:
        c_performance = penalty_data.groupby('param_C')['mean_test_score'].mean()
        ax2.plot(range(len(c_performance)), c_performance.values, marker='o', label=f'{penalty}')

ax2.set_xlabel('C ê°’ (ë¡œê·¸ ìŠ¤ì¼€ì¼)')
ax2.set_ylabel('í‰ê·  CV ì ìˆ˜')
ax2.set_title('C ê°’ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” (Penaltyë³„)')
ax2.set_xticks(range(len(c_performance)))
ax2.set_xticklabels([f'{c:.3f}' for c in c_performance.index], rotation=45)
ax2.legend()
ax2.grid(True, alpha=0.3)

# 4-3. Penaltyë³„ ì„±ëŠ¥ ë¶„í¬
ax3 = axes[0, 2]
penalty_types = results_df['param_penalty'].dropna().unique()
penalty_scores = [results_df[results_df['param_penalty'] == p]['mean_test_score'].values 
                 for p in penalty_types]

box_plot = ax3.boxplot(penalty_scores, labels=penalty_types, patch_artist=True)
colors = ['lightblue', 'lightgreen', 'lightcoral']
for patch, color in zip(box_plot['boxes'], colors[:len(penalty_types)]):
    patch.set_facecolor(color)

ax3.set_xlabel('Penalty ìœ í˜•')
ax3.set_ylabel('CV ì ìˆ˜')
ax3.set_title('Penaltyë³„ ì„±ëŠ¥ ë¶„í¬')
ax3.grid(True, alpha=0.3)

# 4-4. C vs Solver íˆíŠ¸ë§µ (L2 penaltyë§Œ)
ax4 = axes[1, 0]
l2_data = results_df[results_df['param_penalty'] == 'l2']
if len(l2_data) > 0:
    heatmap_data = l2_data.pivot_table(
        values='mean_test_score', 
        index='param_solver', 
        columns='param_C', 
        aggfunc='mean'
    )
    
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='viridis', 
                ax=ax4, cbar_kws={'label': 'CV ì ìˆ˜'})
    ax4.set_title('C vs Solver ì„±ëŠ¥ íˆíŠ¸ë§µ (L2 Penalty)')
    ax4.set_xlabel('C ê°’')
    ax4.set_ylabel('Solver')

# 4-5. ì„±ëŠ¥ í–¥ìƒ ì¶”ì´
ax5 = axes[1, 1]
sorted_results = results_df.sort_values('mean_test_score', ascending=False)
top_n = min(50, len(sorted_results))
ax5.plot(range(1, top_n+1), sorted_results['mean_test_score'].head(top_n), 
         marker='o', markersize=3, alpha=0.7)
ax5.axhline(y=grid_search.best_score_, color='red', linestyle='--', 
           label=f'ìµœê³  ì ìˆ˜: {grid_search.best_score_:.4f}')
ax5.set_xlabel('ìˆœìœ„')
ax5.set_ylabel('CV ì ìˆ˜')
ax5.set_title(f'ìƒìœ„ {top_n}ê°œ ì¡°í•© ì„±ëŠ¥ ë¶„í¬')
ax5.legend()
ax5.grid(True, alpha=0.3)

# 4-6. ê³¼ì í•© ë¶„ì„ (Train vs Validation ì ìˆ˜)
ax6 = axes[1, 2]
train_scores = results_df['mean_train_score']
test_scores = results_df['mean_test_score']

ax6.scatter(train_scores, test_scores, alpha=0.6, s=20)
ax6.plot([0, 1], [0, 1], 'r--', alpha=0.8, label='ì™„ë²½í•œ ì¼ì¹˜ì„ ')

# ìµœê³  ì„±ëŠ¥ ì  ê°•ì¡°
best_idx = results_df['mean_test_score'].idxmax()
best_train = results_df.loc[best_idx, 'mean_train_score']
best_test = results_df.loc[best_idx, 'mean_test_score']
ax6.scatter(best_train, best_test, color='red', s=100, marker='*', 
           label=f'ìµœê³  ì„±ëŠ¥\n({best_train:.3f}, {best_test:.3f})')

ax6.set_xlabel('Train CV ì ìˆ˜')
ax6.set_ylabel('Test CV ì ìˆ˜')
ax6.set_title('ê³¼ì í•© ë¶„ì„ (Train vs Test)')
ax6.legend()
ax6.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 5. Validation Curve - C íŒŒë¼ë¯¸í„° ì„¸ë¶€ ë¶„ì„
print(f"\n4. C íŒŒë¼ë¯¸í„° ì„¸ë¶€ ë¶„ì„")
print("-" * 50)

# ìµœì  solverì™€ penaltyë¡œ C ê°’ë§Œ ë³€ê²½í•˜ë©° ë¶„ì„
best_solver = grid_search.best_params_['solver']
best_penalty = grid_search.best_params_['penalty']

# ElasticNetì˜ ê²½ìš° l1_ratioë„ í•„ìš”
if best_penalty == 'elasticnet':
    best_l1_ratio = grid_search.best_params_['l1_ratio']
    best_max_iter = grid_search.best_params_['max_iter']
    
    model_for_validation = LogisticRegression(
        solver=best_solver, 
        penalty=best_penalty, 
        l1_ratio=best_l1_ratio,
        max_iter=best_max_iter,
        random_state=42
    )
    print(f"ë¶„ì„ ëª¨ë¸: solver={best_solver}, penalty={best_penalty}, l1_ratio={best_l1_ratio}")
else:
    model_for_validation = LogisticRegression(
        solver=best_solver, 
        penalty=best_penalty, 
        random_state=42
    )
    print(f"ë¶„ì„ ëª¨ë¸: solver={best_solver}, penalty={best_penalty}")

C_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]

try:
    train_scores_c, validation_scores_c = validation_curve(
        model_for_validation, X_train_scaled, y_train, 
        param_name='C', param_range=C_range,
        cv=5, scoring='accuracy', n_jobs=-1
    )
    
    # Validation Curve ì‹œê°í™”
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    train_mean = np.mean(train_scores_c, axis=1)
    train_std = np.std(train_scores_c, axis=1)
    validation_mean = np.mean(validation_scores_c, axis=1)
    validation_std = np.std(validation_scores_c, axis=1)

    plt.semilogx(C_range, train_mean, 'o-', color='blue', label='í›ˆë ¨ ì ìˆ˜')
    plt.fill_between(C_range, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')

    plt.semilogx(C_range, validation_mean, 'o-', color='red', label='ê²€ì¦ ì ìˆ˜')
    plt.fill_between(C_range, validation_mean - validation_std, validation_mean + validation_std, alpha=0.1, color='red')

    plt.xlabel('C (ì •ê·œí™” ê°•ë„)')
    plt.ylabel('ì •í™•ë„')
    plt.title(f'Validation Curve')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # C ê°’ë³„ ì„±ëŠ¥ í‘œ - ê°„ë‹¨í•œ ë²„ì „
    plt.subplot(1, 2, 2)
    
    # í…ìŠ¤íŠ¸ë¡œ í‘œ ë§Œë“¤ê¸°
    table_text = "C ê°’ë³„ ì„±ëŠ¥ ë¹„êµ\n" + "="*30 + "\n"
    table_text += f"{'C':<8} {'Train':<7} {'Valid':<7} {'Gap':<6}\n"
    table_text += "-"*30 + "\n"
    
    for i, c in enumerate(C_range):
        train_score = train_mean[i]
        valid_score = validation_mean[i]
        gap = train_score - valid_score
        table_text += f"{c:<8.3f} {train_score:<7.3f} {valid_score:<7.3f} {gap:<6.3f}\n"
    
    plt.text(0.1, 0.9, table_text, transform=plt.gca().transAxes, 
             fontfamily='monospace', fontsize=10, verticalalignment='top')
    plt.axis('off')
    plt.title('C ê°’ë³„ ì„±ëŠ¥ ìƒì„¸í‘œ')

    plt.tight_layout()
    plt.show()
    
except Exception as e:
    print(f"Validation curve ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    print("ëŒ€ì‹  ê°„ë‹¨í•œ C ê°’ ë¹„êµë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    # ëŒ€ì•ˆ: ê°„ë‹¨í•œ C ê°’ ë¹„êµ
    plt.figure(figsize=(10, 6))
    
    c_scores = []
    for c in C_range:
        if best_penalty == 'elasticnet':
            temp_model = LogisticRegression(
                C=c, solver=best_solver, penalty=best_penalty, 
                l1_ratio=best_l1_ratio, max_iter=best_max_iter, random_state=42
            )
        else:
            temp_model = LogisticRegression(
                C=c, solver=best_solver, penalty=best_penalty, random_state=42
            )
        
        scores = cross_val_score(temp_model, X_train_scaled, y_train, cv=5)
        c_scores.append(scores.mean())
    
    plt.semilogx(C_range, c_scores, 'o-', color='green', linewidth=2, markersize=8)
    plt.xlabel('C ê°’')
    plt.ylabel('5-Fold CV ì •í™•ë„')
    plt.title('C íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”')
    plt.grid(True, alpha=0.3)
    
    # ìµœê³  ì„±ëŠ¥ ì§€ì  í‘œì‹œ
    best_c_idx = np.argmax(c_scores)
    plt.scatter(C_range[best_c_idx], c_scores[best_c_idx], 
               color='red', s=100, zorder=5, label=f'ìµœê³  ì„±ëŠ¥: C={C_range[best_c_idx]}')
    plt.legend()
    
    for i, (c, score) in enumerate(zip(C_range, c_scores)):
        plt.annotate(f'{score:.3f}', (c, score), textcoords="offset points", 
                    xytext=(0,10), ha='center', fontsize=9)
    
    plt.tight_layout()
    plt.show()

# 6. ìµœì¢… ê²°ê³¼ ìš”ì•½
print(f"\n5. ìµœì¢… ê²°ê³¼ ìš”ì•½")
print("=" * 50)

print(f"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
for param, value in grid_search.best_params_.items():
    print(f"  {param}: {value}")

print(f"\nì„±ëŠ¥ ê²°ê³¼:")
print(f"  ìµœì  CV ì ìˆ˜: {grid_search.best_score_:.4f} ({grid_search.best_score_*100:.1f}%)")
print(f"  í…ŒìŠ¤íŠ¸ ì ìˆ˜: {test_accuracy:.4f} ({test_accuracy*100:.1f}%)")

# ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ì™€ ë¹„êµ
genetic_score = 0.7406
improvement = grid_search.best_score_ - genetic_score
print(f"\nìœ ì „ ì•Œê³ ë¦¬ì¦˜ê³¼ ë¹„êµ:")
print(f"  ìœ ì „ ì•Œê³ ë¦¬ì¦˜ (ê¸°ë³¸ íŒŒë¼ë¯¸í„°): {genetic_score:.4f} ({genetic_score*100:.1f}%)")
print(f"  í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í›„: {grid_search.best_score_:.4f} ({grid_search.best_score_*100:.1f}%)")
print(f"  ê°œì„  ì •ë„: {improvement:.4f} ({improvement*100:.1f}%p)")

if improvement > 0.02:
    print("  >> í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¡œ ìœ ì˜ë¯¸í•œ ê°œì„ ")
elif improvement > 0:
    print("  >> ì•½ê°„ì˜ ê°œì„ ")
else:
    print("  >> ê°œì„  íš¨ê³¼ ë¯¸ë¯¸ ë˜ëŠ” ì•…í™”")

# ëª©í‘œì™€ ë¹„êµ
target_score = 0.80
gap_to_target = target_score - max(grid_search.best_score_, test_accuracy)
print(f"\n80% ëª©í‘œì™€ ë¹„êµ:")
print(f"  ëª©í‘œê¹Œì§€ ë‚¨ì€ ê²©ì°¨: {gap_to_target*100:.1f}%p")

if gap_to_target <= 0:
    print("  ğŸ¯ ëª©í‘œ ë‹¬ì„±!")
elif gap_to_target <= 0.05:
    print("  ğŸ“ˆ ëª©í‘œì— ë§¤ìš° ê·¼ì ‘")
elif gap_to_target <= 0.1:
    print("  ğŸ“Š ëª©í‘œì— ê·¼ì ‘í•˜ì§€ë§Œ ì¶”ê°€ ê°œì„  í•„ìš”")
else:
    print("  ğŸ“‰ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ë‹¤ë¥¸ ì ‘ê·¼ë²• í•„ìš”")