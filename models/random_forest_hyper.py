import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, accuracy_score, f1_score
import time
import os
import warnings
warnings.filterwarnings('ignore')

# ì•ˆì „í•œ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

print("=== Random Forest Hyperparameter Grid Search ===")
print("ëª©í‘œ: í•œ/ì—´ ì²´ì§ˆ ë¶„ë¥˜ ì„±ëŠ¥ ìµœì í™”")

# ===== ì„¤ì • ì˜µì…˜ =====
# íƒìƒ‰ ë²”ìœ„ ì„¤ì •
SEARCH_MODE = 'full'  # 'fast', 'medium', 'full' ì¤‘ ì„ íƒ

# CPU ì‚¬ìš©ëŸ‰ ì„¤ì • (ì¤‘ìš”!)
CPU_USAGE = 'medium'     # 'low', 'medium', 'high' ì¤‘ ì„ íƒ

print(f"\nì„¤ì •: {SEARCH_MODE} íƒìƒ‰, {CPU_USAGE} CPU ì‚¬ìš©")

# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print("\n1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
X = pd.read_csv('features_left.csv')
y = pd.read_csv('labels_left.csv')

print(f"ë°ì´í„° í¬ê¸°: X{X.shape}, y{y.shape}")
print(f"í´ë˜ìŠ¤ ë¶„í¬:\n{y.value_counts()}")

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42,
    stratify=y
)

# ìŠ¤ì¼€ì¼ë§
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# yë¥¼ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
y_train_flat = np.ravel(y_train)
y_test_flat = np.ravel(y_test)

print(f"í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• : {X_train.shape[0]}/{X_test.shape[0]}")

# 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
print("\n2ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜")

# ì˜µì…˜ 1: ë¹ ë¥¸ íƒìƒ‰ (216ê°œ ì¡°í•©, ì•½ 2ë¶„)
param_grid_fast = {
    'n_estimators': [100, 200],                    # 2ê°œ (ê¸°ë³¸ì ìœ¼ë¡œ ì¢‹ì€ ê°’ë“¤)
    'max_depth': [3, 5, 7],                        # 3ê°œ (ê³¼ì í•© ë°©ì§€)
    'min_samples_split': [2, 5],                   # 2ê°œ
    'min_samples_leaf': [1, 2],                    # 2ê°œ  
    'max_features': ['sqrt', 'log2'],              # 2ê°œ
    'class_weight': ['balanced', None]             # 2ê°œ (ê°€ì¥ íš¨ê³¼ì )
}

# ì˜µì…˜ 2: ì¤‘ê°„ íƒìƒ‰ (540ê°œ ì¡°í•©, ì•½ 5ë¶„)  
param_grid_medium = {
    'n_estimators': [50, 100, 200],                # 3ê°œ
    'max_depth': [3, 5, 7, None],                  # 4ê°œ
    'min_samples_split': [2, 5],                   # 2ê°œ
    'min_samples_leaf': [1, 2],                    # 2ê°œ
    'max_features': ['sqrt', 'log2'],              # 2ê°œ
    'class_weight': ['balanced', None]             # 2ê°œ
}

# ì˜µì…˜ 3: ì „ì²´ íƒìƒ‰ (1620ê°œ ì¡°í•©, ì•½ 15ë¶„)
param_grid_full = {
    'n_estimators': [50, 100, 200, 300],           # 4ê°œ
    'max_depth': [3, 5, 7, 10, None],              # 5ê°œ
    'min_samples_split': [2, 5, 10],               # 3ê°œ
    'min_samples_leaf': [1, 2, 4],                 # 3ê°œ
    'max_features': ['sqrt', 'log2', None],        # 3ê°œ
    'class_weight': ['balanced', 'balanced_subsample', None]  # 3ê°œ
}

# ì›í•˜ëŠ” ì˜µì…˜ ì„ íƒ
if SEARCH_MODE == 'fast':
    param_grid = param_grid_fast
    print("ë¹ ë¥¸ íƒìƒ‰ ëª¨ë“œ ì„ íƒ (216ê°œ ì¡°í•©)")
elif SEARCH_MODE == 'medium':
    param_grid = param_grid_medium  
    print("ì¤‘ê°„ íƒìƒ‰ ëª¨ë“œ ì„ íƒ (540ê°œ ì¡°í•©)")
else:
    param_grid = param_grid_full
    print("ì „ì²´ íƒìƒ‰ ëª¨ë“œ ì„ íƒ (1620ê°œ ì¡°í•©)")

# ì´ ì¡°í•© ê°œìˆ˜ ê³„ì‚°
total_combinations = 1
for key, values in param_grid.items():
    total_combinations *= len(values)
    print(f"{key}: {values}")

print(f"\nì´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ê°œìˆ˜: {total_combinations}ê°œ")
print(f"5-fold CV ì ìš©ì‹œ ì´ ëª¨ë¸ í•™ìŠµ íšŸìˆ˜: {total_combinations * 5}ê°œ")

# 3. CPU ì‚¬ìš©ëŸ‰ ì œì–´ ì„¤ì •
print("\n3ë‹¨ê³„: CPU ì‚¬ìš©ëŸ‰ ì„¤ì •")

if CPU_USAGE == 'low':
    # CPU ì‚¬ìš©ëŸ‰ ìµœì†Œí™” (1-2ì½”ì–´ë§Œ ì‚¬ìš©, ê°€ì¥ ëŠë¦¼)
    rf_n_jobs = 1
    grid_n_jobs = 1
    time_multiplier = 3.0
    print("ì €ì‚¬ìš© ëª¨ë“œ: CPU 1-2ì½”ì–´ë§Œ ì‚¬ìš© (ë‹¤ë¥¸ ì‘ì—… ê°€ëŠ¥)")
elif CPU_USAGE == 'medium':  
    # CPU ì‚¬ìš©ëŸ‰ ì¤‘ê°„ (ì ˆë°˜ ì½”ì–´ ì‚¬ìš©)
    cpu_count = os.cpu_count() or 4
    rf_n_jobs = 1
    grid_n_jobs = max(1, cpu_count // 2)  # ì½”ì–´ì˜ ì ˆë°˜ë§Œ ì‚¬ìš©
    time_multiplier = 1.5
    print(f"ì¤‘ê°„ ì‚¬ìš© ëª¨ë“œ: CPU {grid_n_jobs}ì½”ì–´ ì‚¬ìš© (ì „ì²´ {cpu_count}ì½”ì–´ ì¤‘)")
else:
    # CPU ì‚¬ìš©ëŸ‰ ìµœëŒ€ (ëª¨ë“  ì½”ì–´ ì‚¬ìš©, ê°€ì¥ ë¹ ë¦„)
    rf_n_jobs = 1
    grid_n_jobs = -1
    time_multiplier = 1.0
    print("ê³ ì‚¬ìš© ëª¨ë“œ: ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš© (ë‹¤ë¥¸ ì‘ì—… ì–´ë ¤ì›€)")

# 4. GridSearchCV ì„¤ì •
print("\n4ë‹¨ê³„: GridSearchCV ì„¤ì •")

# ë‹¤ì¤‘ í‰ê°€ ì§€í‘œ ì„¤ì •
scoring = {
    'accuracy': 'accuracy',
    'f1_macro': 'f1_macro',
    'precision_macro': 'precision_macro',
    'recall_macro': 'recall_macro'
}

# 5-fold ì¸µí™” êµì°¨ê²€ì¦
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# GridSearchCV ê°ì²´ ìƒì„± (F1-scoreë¥¼ ì£¼ í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©)
grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42, n_jobs=rf_n_jobs),
    param_grid=param_grid,
    cv=cv,
    scoring=scoring,
    refit='f1_macro',  # ìµœì  ëª¨ë¸ ì„ íƒ ê¸°ì¤€
    n_jobs=grid_n_jobs,  # ì œí•œëœ ë³‘ë ¬ì²˜ë¦¬
    verbose=1,           # ì§„í–‰ìƒí™© ì¶œë ¥
    return_train_score=True
)

# ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
estimated_minutes = (total_combinations * 5 * 0.1 / 60) * time_multiplier

print("GridSearchCV ì„¤ì • ì™„ë£Œ:")
print(f"- êµì°¨ê²€ì¦: {cv.n_splits}-fold Stratified")
print(f"- í‰ê°€ì§€í‘œ: {list(scoring.keys())}")
print(f"- ì¬í•™ìŠµ ê¸°ì¤€: f1_macro")
print(f"- CPU ì‚¬ìš©ëŸ‰: {CPU_USAGE} ëª¨ë“œ ({grid_n_jobs if grid_n_jobs != -1 else 'all'} ì½”ì–´)")
print(f"- ì˜ˆìƒ ì†Œìš”ì‹œê°„: ì•½ {estimated_minutes:.1f}ë¶„")

# 5. Grid Search ì‹¤í–‰
print("\n5ë‹¨ê³„: Grid Search ì‹¤í–‰")
print("â° ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”... (Ctrl+Cë¡œ ì¤‘ë‹¨ ê°€ëŠ¥)")

start_time = time.time()

try:
    grid_search.fit(X_train_scaled, y_train_flat)
    search_time = time.time() - start_time
    
    print(f"\nâœ… Grid Search ì™„ë£Œ!")
    print(f"- ì‹¤ì œ ì†Œìš” ì‹œê°„: {search_time/60:.1f}ë¶„")
    print(f"- í…ŒìŠ¤íŠ¸ëœ ì¡°í•©: {len(grid_search.cv_results_['params'])}ê°œ")
    
except KeyboardInterrupt:
    print(f"\nâ›” ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    print(f"- ì§„í–‰ ì‹œê°„: {(time.time() - start_time)/60:.1f}ë¶„")
    exit()

# 6. ìµœì  ê²°ê³¼ ì¶œë ¥
print("\n=== 6ë‹¨ê³„: ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²°ê³¼ ===")

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("ğŸ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
for param, value in best_params.items():
    print(f"  {param}: {value}")

print(f"\nğŸ“Š ìµœê³  êµì°¨ê²€ì¦ F1-Score: {best_score:.4f}")

# ìµœì  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_scaled)

test_accuracy = accuracy_score(y_test_flat, y_pred_best)
test_f1 = f1_score(y_test_flat, y_pred_best, average='macro')

print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥:")
print(f"  ì •í™•ë„: {test_accuracy:.4f} ({test_accuracy*100:.1f}%)")
print(f"  F1-Score: {test_f1:.4f}")

print(f"\nğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(y_test_flat, y_pred_best))

# 7. ìƒìœ„ ëª¨ë¸ë“¤ ë¹„êµ
print("\n=== 7ë‹¨ê³„: ìƒìœ„ ì„±ëŠ¥ ëª¨ë¸ë“¤ ë¹„êµ ===")

results_df = pd.DataFrame(grid_search.cv_results_)

# F1-score ê¸°ì¤€ ìƒìœ„ 10ê°œ ëª¨ë¸
top_models = results_df.nlargest(10, 'mean_test_f1_macro')

print("ğŸ† F1-Score ê¸°ì¤€ ìƒìœ„ 10ê°œ ëª¨ë¸:")
print("-" * 120)
print(f"{'ìˆœìœ„':<4} {'F1-Score':<10} {'ì •í™•ë„':<8} {'n_est':<6} {'depth':<6} {'split':<6} {'leaf':<5} {'features':<8} {'weight':<12}")
print("-" * 120)

for idx, (i, row) in enumerate(top_models.iterrows()):
    print(f"{idx+1:<4} {row['mean_test_f1_macro']:<10.4f} "
          f"{row['mean_test_accuracy']:<8.4f} "
          f"{row['param_n_estimators']:<6} "
          f"{str(row['param_max_depth']):<6} "
          f"{row['param_min_samples_split']:<6} "
          f"{row['param_min_samples_leaf']:<5} "
          f"{str(row['param_max_features']):<8} "
          f"{str(row['param_class_weight']):<12}")

# 8. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
print("\n=== 8ë‹¨ê³„: ìµœì  ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ ===")

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': best_model.feature_importances_
}).sort_values('importance', ascending=False)

print("ğŸ” ìƒìœ„ 10ê°œ ì¤‘ìš”í•œ íŠ¹ì„±:")
print("-" * 50)
for i in range(min(10, len(feature_importance))):
    row = feature_importance.iloc[i]
    print(f"{i+1:2d}. {row['feature']:<30} : {row['importance']:.4f}")

# 9. ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜
def plot_grid_search_results(grid_search, param1, param2, score='f1_macro'):
    """ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”"""
    
    results_df = pd.DataFrame(grid_search.cv_results_)
    score_key = f'mean_test_{score}'
    
    # ì»¬ëŸ¼ëª… í™•ì¸
    param1_col = f'param_{param1}'
    param2_col = f'param_{param2}'
    
    if param1_col in results_df.columns and param2_col in results_df.columns:
        # ìœ ë‹ˆí¬í•œ ê°’ë“¤ì´ ì¶©ë¶„í•œì§€ í™•ì¸
        unique_param1 = results_df[param1_col].nunique()
        unique_param2 = results_df[param2_col].nunique()
        
        if unique_param1 > 1 and unique_param2 > 1:
            pivot_table = results_df.pivot_table(
                values=score_key,
                index=param1_col,
                columns=param2_col,
                aggfunc='mean'
            )
            
            plt.figure(figsize=(12, 8))
            sns.heatmap(pivot_table, annot=True, fmt='.4f', cmap='viridis',
                        cbar_kws={'label': f'{score.replace("_", " ").title()}'})
            
            plt.title(f'Random Forest Grid Search Results\n({param1} vs {param2})', 
                      fontsize=14, fontweight='bold')
            plt.xlabel(param2.replace('_', ' ').title(), fontweight='bold')
            plt.ylabel(param1.replace('_', ' ').title(), fontweight='bold')
            
            plt.tight_layout()
            filename = f'rf_gridsearch_{param1}_{param2}_{score}.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ íˆíŠ¸ë§µì´ '{filename}'ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            plt.show()
            
            return pivot_table
        else:
            print(f"âš ï¸ íŒŒë¼ë¯¸í„° ì¡°í•©ì´ ì¶©ë¶„í•˜ì§€ ì•Šì•„ íˆíŠ¸ë§µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    else:
        print(f"âš ï¸ íŒŒë¼ë¯¸í„° '{param1}' ë˜ëŠ” '{param2}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

# 10. ì£¼ìš” íŒŒë¼ë¯¸í„° ì¡°í•© ì‹œê°í™”
print("\n=== 9ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™” ===")

try:
    # n_estimators vs max_depth íˆíŠ¸ë§µ
    plot_grid_search_results(grid_search, 'n_estimators', 'max_depth', 'f1_macro')
    
    # min_samples_split vs min_samples_leaf íˆíŠ¸ë§µ  
    plot_grid_search_results(grid_search, 'min_samples_split', 'min_samples_leaf', 'f1_macro')
except Exception as e:
    print(f"âš ï¸ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("íˆíŠ¸ë§µ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

# 11. ì„±ëŠ¥ í–¥ìƒ ìš”ì•½
print("\n=== ğŸ‰ ìµœì¢… ìš”ì•½ ===")
print(f"ê¸°ì¡´ Random Forest ì„±ëŠ¥:     67% (F1: 0.66)")
print(f"ìµœì í™”ëœ Random Forest ì„±ëŠ¥:  {test_accuracy*100:.1f}% (F1: {test_f1:.4f})")

improvement_acc = test_accuracy*100 - 67
improvement_f1 = test_f1 - 0.66

if improvement_acc > 0:
    print(f"ğŸš€ ì„±ëŠ¥ í–¥ìƒ:                   +{improvement_acc:.1f}%p (F1: {improvement_f1:+.4f})")
else:
    print(f"ğŸ“‰ ì„±ëŠ¥ ë³€í™”:                   {improvement_acc:.1f}%p (F1: {improvement_f1:+.4f})")

print(f"\nğŸ’¡ ì¶”ì²œ í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
for param, value in best_params.items():
    print(f"  {param}: {value}")

print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {search_time/60:.1f}ë¶„")
print(f"ğŸ’» CPU ì‚¬ìš© ëª¨ë“œ: {CPU_USAGE}")
print(f"ğŸ” íƒìƒ‰ ë²”ìœ„: {SEARCH_MODE}")

print("\nğŸ“ ì°¸ê³ ì‚¬í•­:")
print("- ì†Œê·œëª¨ ë°ì´í„°ì…‹(90ê°œ)ì—ì„œëŠ” ê³¼ì í•© ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
print("- ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤")
print("- ë‹¤ë¥¸ íŠ¹ì„± ì¡°í•©ì´ë‚˜ ì „ì²˜ë¦¬ ë°©ë²•ë„ ê³ ë ¤í•´ë³´ì„¸ìš”")

# ëª¨ë“  í”Œë¡¯ ì°½ ë‹«ê¸°
plt.close('all')