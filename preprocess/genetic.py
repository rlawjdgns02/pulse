import pandas as pd
import numpy as np
import random
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
import time
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("=== ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ ===")
print("ëª©í‘œ: 80% ì„±ëŠ¥ ë‹¬ì„±ì„ ìœ„í•œ ìµœì  íŠ¹ì„± ì¡°í•© ì°¾ê¸°")

class GeneticFeatureSelector:
    def __init__(self, X, y, model_type='svm', population_size=50, 
                 generations=100, mutation_rate=0.1, crossover_rate=0.8,
                 min_features=3, max_features=15, cv_folds=5):
        """
        ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ íŠ¹ì„± ì„ íƒê¸°
        
        Parameters:
        - X, y: ë°ì´í„°ì™€ ë¼ë²¨
        - model_type: 'svm', 'rf', 'lr' ì¤‘ ì„ íƒ
        - population_size: ê°œì²´êµ° í¬ê¸°
        - generations: ì„¸ëŒ€ ìˆ˜
        - mutation_rate: ëŒì—°ë³€ì´ í™•ë¥ 
        - crossover_rate: êµë°° í™•ë¥ 
        - min_features, max_features: íŠ¹ì„± ê°œìˆ˜ ë²”ìœ„
        - cv_folds: êµì°¨ê²€ì¦ í´ë“œ ìˆ˜
        """
        self.X = X
        self.y = y
        self.feature_names = X.columns.tolist()
        self.n_features = len(self.feature_names)
        
        self.population_size = population_size
        self.generations = generations
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.min_features = min_features
        self.max_features = max_features
        self.cv_folds = cv_folds
        
        # ëª¨ë¸ ì„¤ì •
        if model_type == 'svm':
            self.model = SVC(kernel='rbf', random_state=42)
        elif model_type == 'rf':
            self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif model_type == 'lr':
            self.model = LogisticRegression(random_state=42, max_iter=1000)
        
        self.scaler = StandardScaler()
        
        # ê²°ê³¼ ì €ì¥
        self.best_fitness_history = []
        self.avg_fitness_history = []
        self.best_individual = None
        self.best_fitness = 0
        
    def create_individual(self):
        """ê°œì²´ ìƒì„± (íŠ¹ì„± ì„ íƒ ë§ˆìŠ¤í¬)"""
        n_selected = random.randint(self.min_features, self.max_features)
        individual = [0] * self.n_features
        selected_indices = random.sample(range(self.n_features), n_selected)
        for idx in selected_indices:
            individual[idx] = 1
        return individual
    
    def create_population(self):
        """ì´ˆê¸° ê°œì²´êµ° ìƒì„±"""
        return [self.create_individual() for _ in range(self.population_size)]
    
    def evaluate_fitness(self, individual):
        """ì í•©ë„ í‰ê°€ (êµì°¨ê²€ì¦ ì„±ëŠ¥)"""
        selected_features = [i for i, gene in enumerate(individual) if gene == 1]
        
        if len(selected_features) == 0:
            return 0
        
        X_selected = self.X.iloc[:, selected_features]
        
        try:
            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
            X_scaled = self.scaler.fit_transform(X_selected)
            
            # êµì°¨ê²€ì¦ ìˆ˜í–‰
            cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=42)
            scores = cross_val_score(self.model, X_scaled, self.y, cv=cv, scoring='accuracy')
            
            fitness = scores.mean()
            
            # íŠ¹ì„± ê°œìˆ˜ì— ë”°ë¥¸ íŒ¨ë„í‹° (ë„ˆë¬´ ë§ì€ íŠ¹ì„± ì‚¬ìš© ë°©ì§€)
            if len(selected_features) > self.max_features * 0.8:
                fitness *= 0.95
                
            return fitness
            
        except Exception as e:
            return 0
    
    def tournament_selection(self, population, fitnesses, tournament_size=3):
        """í† ë„ˆë¨¼íŠ¸ ì„ íƒ"""
        selected = []
        for _ in range(len(population)):
            tournament_indices = random.sample(range(len(population)), tournament_size)
            tournament_fitnesses = [fitnesses[i] for i in tournament_indices]
            winner_idx = tournament_indices[np.argmax(tournament_fitnesses)]
            selected.append(population[winner_idx].copy())
        return selected
    
    def crossover(self, parent1, parent2):
        """êµë°° (ë‹¨ì¼ì  êµì°¨)"""
        if random.random() > self.crossover_rate:
            return parent1.copy(), parent2.copy()
        
        crossover_point = random.randint(1, len(parent1) - 1)
        
        child1 = parent1[:crossover_point] + parent2[crossover_point:]
        child2 = parent2[:crossover_point] + parent1[crossover_point:]
        
        # íŠ¹ì„± ê°œìˆ˜ ì œí•œ í™•ì¸
        self._adjust_feature_count(child1)
        self._adjust_feature_count(child2)
        
        return child1, child2
    
    def _adjust_feature_count(self, individual):
        """íŠ¹ì„± ê°œìˆ˜ë¥¼ ë²”ìœ„ ë‚´ë¡œ ì¡°ì •"""
        n_selected = sum(individual)
        
        if n_selected < self.min_features:
            # íŠ¹ì„± ì¶”ê°€
            available_indices = [i for i, gene in enumerate(individual) if gene == 0]
            to_add = min(self.min_features - n_selected, len(available_indices))
            add_indices = random.sample(available_indices, to_add)
            for idx in add_indices:
                individual[idx] = 1
                
        elif n_selected > self.max_features:
            # íŠ¹ì„± ì œê±°
            selected_indices = [i for i, gene in enumerate(individual) if gene == 1]
            to_remove = n_selected - self.max_features
            remove_indices = random.sample(selected_indices, to_remove)
            for idx in remove_indices:
                individual[idx] = 0
    
    def mutate(self, individual):
        """ëŒì—°ë³€ì´"""
        mutated = individual.copy()
        
        for i in range(len(mutated)):
            if random.random() < self.mutation_rate:
                mutated[i] = 1 - mutated[i]  # ë¹„íŠ¸ í”Œë¦½
        
        # íŠ¹ì„± ê°œìˆ˜ ì œí•œ í™•ì¸
        self._adjust_feature_count(mutated)
        
        return mutated
    
    def evolve(self):
        """ì§„í™” ê³¼ì • ì‹¤í–‰"""
        print(f"ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì‹œì‘:")
        print(f"- ê°œì²´êµ° í¬ê¸°: {self.population_size}")
        print(f"- ì„¸ëŒ€ ìˆ˜: {self.generations}")
        print(f"- íŠ¹ì„± ë²”ìœ„: {self.min_features}-{self.max_features}ê°œ")
        print(f"- êµë°°ìœ¨: {self.crossover_rate}, ëŒì—°ë³€ì´ìœ¨: {self.mutation_rate}")
        
        # ì´ˆê¸° ê°œì²´êµ° ìƒì„±
        population = self.create_population()
        
        for generation in range(self.generations):
            # ì í•©ë„ í‰ê°€
            fitnesses = [self.evaluate_fitness(individual) for individual in population]
            
            # ìµœê³  ê°œì²´ ê¸°ë¡
            max_fitness_idx = np.argmax(fitnesses)
            if fitnesses[max_fitness_idx] > self.best_fitness:
                self.best_fitness = fitnesses[max_fitness_idx]
                self.best_individual = population[max_fitness_idx].copy()
            
            # í†µê³„ ê¸°ë¡
            self.best_fitness_history.append(max(fitnesses))
            self.avg_fitness_history.append(np.mean(fitnesses))
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if generation % 10 == 0 or generation == self.generations - 1:
                selected_count = sum(self.best_individual) if self.best_individual else 0
                print(f"ì„¸ëŒ€ {generation:3d}: ìµœê³  ì í•©ë„ {self.best_fitness:.4f} "
                      f"(íŠ¹ì„± {selected_count}ê°œ), í‰ê·  {np.mean(fitnesses):.4f}")
            
            if generation == self.generations - 1:
                break
                
            # ì„ íƒ
            selected_population = self.tournament_selection(population, fitnesses)
            
            # êµë°° ë° ëŒì—°ë³€ì´
            new_population = []
            for i in range(0, len(selected_population), 2):
                parent1 = selected_population[i]
                parent2 = selected_population[min(i+1, len(selected_population)-1)]
                
                child1, child2 = self.crossover(parent1, parent2)
                child1 = self.mutate(child1)
                child2 = self.mutate(child2)
                
                new_population.extend([child1, child2])
            
            population = new_population[:self.population_size]
        
        return self.get_best_features()
    
    def get_best_features(self):
        """ìµœì  íŠ¹ì„± ë°˜í™˜"""
        if self.best_individual is None:
            return []
        
        selected_indices = [i for i, gene in enumerate(self.best_individual) if gene == 1]
        selected_features = [self.feature_names[i] for i in selected_indices]
        
        return {
            'features': selected_features,
            'feature_indices': selected_indices,
            'fitness': self.best_fitness,
            'n_features': len(selected_features)
        }
    
    def plot_evolution(self):
        """ì§„í™” ê³¼ì • ì‹œê°í™”"""
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        plt.plot(self.best_fitness_history, label='ìµœê³  ì í•©ë„', color='red', linewidth=2)
        plt.plot(self.avg_fitness_history, label='í‰ê·  ì í•©ë„', color='blue', alpha=0.7)
        plt.xlabel('ì„¸ëŒ€')
        plt.ylabel('ì í•©ë„ (ì •í™•ë„)')
        plt.title('ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì§„í™” ê³¼ì •')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.subplot(1, 2, 2)
        generation_improvements = []
        best_so_far = 0
        for fitness in self.best_fitness_history:
            if fitness > best_so_far:
                best_so_far = fitness
                generation_improvements.append(len(generation_improvements))
        
        if generation_improvements:
            improvement_values = [self.best_fitness_history[gen] for gen in generation_improvements]
            plt.scatter(generation_improvements, improvement_values, color='red', s=50, alpha=0.7)
            plt.plot(generation_improvements, improvement_values, color='red', alpha=0.5)
            plt.xlabel('ì„¸ëŒ€')
            plt.ylabel('ê°œì„ ëœ ì í•©ë„')
            plt.title('ì„±ëŠ¥ ê°œì„  ì§€ì ')
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

# ë°ì´í„° ë¡œë“œ
X = pd.read_csv('data/all_features_left.csv')  # ë˜ëŠ” features_right.csvë¡œ ë³€ê²½
y = pd.read_csv('data/labels_all_left.csv')
y = y.astype(int)

# ë¼ë²¨ ì²˜ë¦¬
y_flat = np.ravel(y)
if set(np.unique(y_flat)) == {1, 2}:
    y_flat = y_flat - 1
    print("ë¼ë²¨ ë³€í™˜: {1,2} â†’ {0,1}")

print(f"ë°ì´í„° í¬ê¸°: {X.shape}")
print(f"í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_flat)}")

# ===== CPU ì‚¬ìš©ëŸ‰ ì œì–´ ì„¤ì • =====
CPU_USAGE = 'medium'  # 'low', 'medium', 'high' ì¤‘ ì„ íƒ
print(f"CPU ì‚¬ìš© ëª¨ë“œ: {CPU_USAGE}")

import os
if CPU_USAGE == 'low':
    n_jobs_setting = 1
    population_size = 20
    generations = 30
    print("ğŸŒ ì €ì‚¬ìš© ëª¨ë“œ: 1ì½”ì–´, ì‘ì€ íƒìƒ‰ ê³µê°„")
elif CPU_USAGE == 'medium':
    cpu_count = os.cpu_count() or 4
    n_jobs_setting = max(1, cpu_count // 2)
    population_size = 30
    generations = 50
    print(f"âš–ï¸ ì¤‘ê°„ ì‚¬ìš© ëª¨ë“œ: {n_jobs_setting}ì½”ì–´")
else:
    n_jobs_setting = -1
    population_size = 50
    generations = 100
    print("ğŸš€ ê³ ì‚¬ìš© ëª¨ë“œ: ëª¨ë“  ì½”ì–´ ì‚¬ìš©")

# CPU ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ íŒŒë¼ë¯¸í„° ì„¤ì •
if CPU_USAGE == 'low':
    population_size = 20
    generations = 30
elif CPU_USAGE == 'medium':
    population_size = 30
    generations = 50
else:  # high
    population_size = 50
    generations = 100

# ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ (ì—¬ëŸ¬ ëª¨ë¸ë¡œ ì‹œë„)
models_to_try = ['svm', 'rf', 'lr']
results = {}

for model_type in models_to_try:
    print(f"\n{'='*60}")
    print(f"{model_type.upper()} ëª¨ë¸ë¡œ ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰")
    print(f"{'='*60}")
    
    # ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì„¤ì • (CPU ì‚¬ìš©ëŸ‰ì— ë§ê²Œ ë™ì  ì¡°ì •)
    # ë°ì´í„° íŠ¹ì„± ìˆ˜ì— ë§ê²Œ ìµœëŒ€ íŠ¹ì„± ìˆ˜ ì¡°ì •
    max_possible_features = min(50, X.shape[1] - 1)  # ì „ì²´ íŠ¹ì„± ìˆ˜ë³´ë‹¤ ì‘ê²Œ ì„¤ì •
    min_possible_features = min(3, max_possible_features)  # ìµœì†Œê°’ë„ ì¡°ì •
    
    ga = GeneticFeatureSelector(
        X=X, 
        y=y_flat,
        model_type=model_type,
        population_size=population_size,  # CPU ëª¨ë“œì— ë”°ë¼ ì¡°ì •ë¨
        generations=generations,          # CPU ëª¨ë“œì— ë”°ë¼ ì¡°ì •ë¨
        mutation_rate=0.15,      # ë†’ì€ ëŒì—°ë³€ì´ìœ¨ (ë‹¤ì–‘ì„± í™•ë³´)
        crossover_rate=0.8,
        min_features=min_possible_features,  # ë™ì ìœ¼ë¡œ ì¡°ì •
        max_features=max_possible_features,  # ë™ì ìœ¼ë¡œ ì¡°ì •
        cv_folds=3               # CPU ì ˆì•½ì„ ìœ„í•´ 3-foldë¡œ ê³ ì •
    )
    
    start_time = time.time()
    best_result = ga.evolve()
    end_time = time.time()
    
    results[model_type] = best_result
    
    print(f"\n{model_type.upper()} ê²°ê³¼:")
    print(f"- ìµœê³  ì„±ëŠ¥: {best_result['fitness']:.4f} ({best_result['fitness']*100:.1f}%)")
    print(f"- ì„ íƒëœ íŠ¹ì„± ìˆ˜: {best_result['n_features']}ê°œ")
    print(f"- ì†Œìš” ì‹œê°„: {end_time - start_time:.1f}ì´ˆ")
    print(f"- ì„ íƒëœ íŠ¹ì„±:")
    for i, feature in enumerate(best_result['features'], 1):
        print(f"  {i:2d}. {feature}")
    
    # ì§„í™” ê³¼ì • ì‹œê°í™”
    ga.plot_evolution()

# ìµœì¢… ê²°ê³¼ ë¹„êµ
print(f"\n{'='*60}")
print("ìµœì¢… ê²°ê³¼ ë¹„êµ")
print(f"{'='*60}")

# ê²°ê³¼ ì •ë ¬ (ì„±ëŠ¥ìˆœ)
sorted_results = sorted(results.items(), key=lambda x: x[1]['fitness'], reverse=True)

print(f"\nì„±ëŠ¥ ìˆœìœ„:")
for rank, (model, result) in enumerate(sorted_results, 1):
    print(f"{rank}. {model.upper()}: {result['fitness']:.4f} ({result['fitness']*100:.1f}%) "
          f"- {result['n_features']}ê°œ íŠ¹ì„±")

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìƒì„¸ ì •ë³´
best_model, best_result = sorted_results[0]
print(f"\nìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model.upper()}")
print(f"ì„±ëŠ¥: {best_result['fitness']:.4f} ({best_result['fitness']*100:.1f}%)")
print(f"ì„ íƒëœ íŠ¹ì„± ({best_result['n_features']}ê°œ):")
for i, feature in enumerate(best_result['features'], 1):
    print(f"  {i:2d}. {feature}")

# ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
target_accuracy = 0.80
if best_result['fitness'] >= target_accuracy:
    print(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±! {best_result['fitness']*100:.1f}% >= 80%")
else:
    gap = target_accuracy - best_result['fitness']
    print(f"\nğŸ“Š ëª©í‘œê¹Œì§€ {gap*100:.1f}%p ë¶€ì¡± (í˜„ì¬: {best_result['fitness']*100:.1f}%)")

# ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì½”ë“œ ì¶œë ¥
print(f"\nğŸ’¾ ìµœì  ì„¤ì • (ë³µì‚¬ìš©):")
print(f"best_features = {best_result['features']}")
print(f"best_model_type = '{best_model}'")
print(f"expected_performance = {best_result['fitness']:.4f}")

print(f"\nâœ… ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ ì™„ë£Œ!")